{"timestamp": 1765439105.2894976, "value": {"paperId": "63e1d03d504bda4ebc08c61ea3a531e983ae8726", "externalIds": {"ArXiv": "2404.16212", "DBLP": "journals/corr/abs-2404-16212", "DOI": "10.1109/SP54263.2024.00194", "CorpusId": 269215824}, "url": "https://www.semanticscholar.org/paper/63e1d03d504bda4ebc08c61ea3a531e983ae8726", "title": "An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape", "venue": "IEEE Symposium on Security and Privacy", "year": 2024, "referenceCount": 82, "citationCount": 31, "openAccessPdf": {"url": "https://arxiv.org/pdf/2404.16212", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2404.16212, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-04-24", "authors": [{"authorId": "2184572952", "name": "Sifat Muhammad Abdullah"}, {"authorId": "2359736", "name": "Aravind Cheruvu"}, {"authorId": "2069475624", "name": "Shravya Kanchi"}, {"authorId": "2297206425", "name": "Taejoong Chung"}, {"authorId": "2297340534", "name": "Peng Gao"}, {"authorId": "2235825", "name": "Murtuza Jadliwala"}, {"authorId": "2264455945", "name": "Bimal Viswanath"}, {"authorId": "2294723807", "name": "Virginia Tech"}, {"authorId": "2297207846", "name": "UT San"}], "abstract": "Deepfake or synthetic images produced using deep generative models pose serious risks to online platforms. This has triggered several research efforts to accurately detect deepfake images, achieving excellent performance on publicly available deepfake datasets. In this work, we study 8 state-of-the-art detectors and argue that they are far from being ready for deployment due to two recent developments. First, the emergence of lightweight methods to customize large generative models, can enable an attacker to create many customized generators (to create deepfakes), thereby substantially increasing the threat surface. We show that existing defenses fail to generalize well to such user-customized generative models that are publicly available today. We discuss new machine learning approaches based on content-agnostic features, and ensemble modeling to improve generalization performance against user-customized models. Second, the emergence of vision foundation models\u2014machine learning models trained on broad data that can be easily adapted to several downstream tasks\u2014can be misused by attackers to craft adversarial deepfakes that can evade existing defenses. We propose a simple adversarial attack that leverages existing foundation models to craft adversarial samples without adding any adversarial noise, through careful semantic manipulation of the image content. We highlight the vulnerabilities of several defenses against our attack, and explore directions leveraging advanced foundation models and adversarial training to defend against this new threat."}}